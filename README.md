# Ideas to write better prompts

## What the LLM can do:


*If you want to learn how to write effective prompts that inspire thoughtful responses and engage your audience, you've come to the right place. In this repository, we'll explore the key elements of successful prompts and provide tips and examples to help you create prompts that are clear, concise, and motivating. Whether you're a teacher, writer, or content creator, the insights and strategies shared here can help you craft prompts that elicit the best possible outcomes from your audience.*


This was a text generated by ChatGPT. Really cool! Besides ChatGPT, which is the most prominent LLM, there are others like OpenAssistant and the new Bing chat. This repository is for my personal use, so I'm not explaining big stuff here, others have done that much better. The goal is simply to write better prompts. Maybe there is something here.

## English vs. Other Languages

[GPT detectors are biased against non-native English writers](https://arxiv.org/pdf/2304.02819.pdf)

<p align="center">
  <img src="https://github.com/grensen/prompting/blob/main/figures/gpt_detectors.png">
</p>

ChatGPT as the most prominent example can speak over [95 languages](https://twitter.com/DataChaz/status/1629766184328364034), no idea how many there are at this point, but the chance are very high that ChatGPT also speaks your language, even if it is a programming language.

But as it turns out, english is by far the most powerful language. You can see this in Bing Chat, for example, how my prompt written in German is translated into English when you search. The reason is simply a much higher accuracy in english. As a non-native English speaker, I should probably keep the results of the paper in my mind. But word diversity seems difficult. If I want to explain a very complex topic, it is not very helpful and certainly not professional if I use different terms for one meaning every time.

**English can be a big advantage, even if you prefer to prompt in other languages like I do.**

## Negation

I wasted hours telling ChatGPT what I don't want. [This article](https://www.quantamagazine.org/ai-like-chatgpt-are-no-good-at-not-20230512/) addresses the problem somewhat. 
Probably it is similar to us humans: Negation can lead to misunderstanding and sometimes even be misused to create it.

**Negation seems to work against the probability for better prompts.**


## Step by Step

<p align="center">
  <img src="https://github.com/grensen/prompting/blob/main/figures/kaparthy_step_by_step.png?raw=true">
</p>
[State of GPT with Andrej Karpathy](https://build.microsoft.com/en-US/sessions/db3f4859-cd30-4445-a0cd-553c3304f8e2)
Just telling the LLM "explain step by step"  can lead to completely different results, as shown in the picture. You can also tell the LLM to be an expert in the field, this can also improve the output. But be careful, in the video it is explained why you should not simply generate an output that is equal to an IQ of 400.



## GPT-4 details leaked

<p align="center">
  <img src="https://github.com/grensen/prompting/blob/main/figures/gpt4_details.png">
</p>

[The GPT-4 Leak](https://www.reddit.com/r/LocalLLaMA/comments/14wbmio/gpt4_details_leaked/) 

The details about GPT-4 may or may not be correct. The problem anyway: The outputs are almost always different. 
Actually everything seems to be from Google somehow, with [Attention Is All You Need](https://arxiv.org/abs/1706.03762) and [Mixture-of-Experts (MoEs)](https://ai.googleblog.com/2022/11/mixture-of-experts-with-expert-choice.html).
But Google does not seem to be lucky, if this is true: [all authors of google's key "attention is all u need" paper have left](https://twitter.com/rachelmetz/status/1678813311528206358).


## You Can Do It Better ChatGPT!

Sometimes, when nothing helps, you can motivate the LLM by spamming it with phrases like "you can do better" and reminding the context that the next output will be more like the one you want. It may seem awkward, but keep in mind that different prompt outputs are produced each time, differing slightly not only in kind, but also in accuracy. And here, what we have to expect is probably normal distributed. That means, with many trials, we might get lucky now and then and produce particularly good output results.

## Dont waste time!

Sometimes you might not want to take an LLM for your work. Interpolation and extrapolation are strange terms, where interpolation means what we have now, and extrapolation is the way that somehow goes beyond our frame.
An LLM was trained with stuff, by that I mean a lot of text, text that was not read. In my mind, such an LLM forms an average of the trained examples. So what has been trained often it can do particularly well, but at the borders it can quickly come to some problems, and beyond the borders confused outputs are rather the rule.

LLM's not only struggle with lack of training examples, they also have to keep up with our world. ChatGPT has been trained a few times so far. However, new methods will only be learned with the next update, and will then be on the outer edge of my mental map. Here I seem to have been more often, because the results were confused and have cost me time!

**Sometimes better you do!**
