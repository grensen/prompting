# Ideas to write better prompts

## What the LLM can do:


*If you want to learn how to write effective prompts that inspire thoughtful responses and engage your audience, you've come to the right place. In this repository, we'll explore the key elements of successful prompts and provide tips and examples to help you create prompts that are clear, concise, and motivating. Whether you're a teacher, writer, or content creator, the insights and strategies shared here can help you craft prompts that elicit the best possible outcomes from your audience.*


This was a text generated by ChatGPT. Really cool! Besides ChatGPT, which is the most prominent LLM, there are others like OpenAssistant and the new Bing chat. This repository is for my personal use, so I'm not explaining big stuff here, others have done that much better. The goal is simply to write better prompts. Maybe there is something here.

## English vs. Other Languages

[GPT detectors are biased against non-native English writers](https://arxiv.org/pdf/2304.02819.pdf)

<p align="center">
  <img src="https://github.com/grensen/prompting/blob/main/figures/gpt_detectors.png">
</p>

ChatGPT as the most prominent example can speak over [95 languages](https://twitter.com/DataChaz/status/1629766184328364034), no idea how many there are at this point, but the chance are very high that ChatGPT also speaks your language, even if it is a programming language.

But as it turns out, english is by far the most powerful language. You can see this in Bing Chat, for example, how my prompt written in German is translated into English when you search. The reason is simply a much higher accuracy in english. As a non-native English speaker, I should probably keep the results of the paper in my mind. But word diversity seems difficult. If I want to explain a very complex topic, it is not very helpful and certainly not professional if I use different terms for one meaning every time.

**English can be a big advantage, even if you prefer to prompt in other languages like I do.**

## Negation

I wasted hours telling ChatGPT what I don't want. [This article](https://www.quantamagazine.org/ai-like-chatgpt-are-no-good-at-not-20230512/) addresses the problem somewhat. 
Probably it is similar to us humans: Negation can lead to misunderstanding and sometimes even be misused to create it.

**Negation seems to work against the probability for better prompts.**


## Step by Step

<p align="center">
  <img src="https://github.com/grensen/prompting/blob/main/figures/kaparthy_step_by_step.png?raw=true">
</p>

[State of GPT with Andrej Karpathy](https://build.microsoft.com/en-US/sessions/db3f4859-cd30-4445-a0cd-553c3304f8e2)
Just telling the LLM "explain step by step"  can lead to completely different results, as shown in the picture. You can also tell the LLM to be an expert in the field, this can also improve the output. But be careful, in the video it is explained why you should not simply generate an output that is equal to an IQ of 400.



## GPT-4 details leaked

<p align="center">
  <img src="https://github.com/grensen/prompting/blob/main/figures/gpt4_details.png">
</p>

[The GPT-4 Leak](https://www.reddit.com/r/LocalLLaMA/comments/14wbmio/gpt4_details_leaked/) 

The details about GPT-4 may or may not be correct. The problem anyway: The outputs are almost always different. 
Actually everything seems to be from Google somehow, with [Attention Is All You Need](https://arxiv.org/abs/1706.03762) and [Mixture-of-Experts (MoEs)](https://ai.googleblog.com/2022/11/mixture-of-experts-with-expert-choice.html).
But Google does not seem to be lucky, if this is true: [all authors of google's key "attention is all u need" paper have left](https://twitter.com/rachelmetz/status/1678813311528206358).

## You Can Do It Better ChatGPT!

Sometimes, when nothing helps, you can motivate the LLM by spamming it with phrases like "you can do better" and reminding the context that the next output will be more like the one you want. It may seem awkward, but keep in mind that different prompt outputs are produced each time, differing slightly not only in kind, but also in accuracy. And here, what we have to expect is probably normal distributed. That means, with many trials, we might get lucky now and then and produce particularly good output results.

## The GPT Output is Not Reproducible, Most of the Time!

<p align="center">
  <img src="https://github.com/grensen/prompting/blob/main/figures/reproducibility_floating_error_problem.png">
</p>

A big problem is the output of ChatGPT, which is not reproducible in most cases. This makes it difficult, especially for topics where you don't know enough to distinguish good and bad information. ChatGPT is, as I write this, one year old. It has changed in many ways over that time, which also requires us to adapt to keep pace. 

## Floating Point Errors in Practice
~~~cs
float[] array = new float[10];
for (int i = 0; i < array.Length; i++)
{
    array[i] = 0.01f * (i + 1);
}
float a = 0, b = 0;
for (int i = 0; i < 10; i++)
{
    a += array[i];
    b += array[9 - i];
}
System.Console.WriteLine("a = " + a + " b = " + b);
// output: a = 0.55 b = 0.54999995
~~~

This is what happens in practice, but the order of calculation is broken by the many processors involved. About ~10% of the results seem to be affected, and that with an incredible amount of calculations. GPT-4 is rumored to be run with 175 trillion weights or parameters. The result is usually a different output with the same input prompt. 

You can try this out on [Fiddle](https://dotnetfiddle.net/)

<p align="center">
  <img src="https://github.com/grensen/multi-core/blob/main/figures/dotnetfiddle_floating_point_issue.png?raw=true">
</p>

This problem is a fundamental one in our systems and is due to the fact that the conversion from 0s and 1s to floating point numbers is not completely round. 

## What ChatGPT Says
<p align="center">
  <img src="https://github.com/grensen/multi-core/blob/main/figures/chatGPT_floating_point_issue.png?raw=true">
</p>

Well, how can we solve it? Perhaps a new development could be the solution, Analog Iterative Machines (AIM). But until then, it will be difficult to justify AI work as science. Somewhere it said that GPT-4 should get an adjustable seed, if that works reliably my thoughts could be obsolete.

## LLM's Get Nerfed

<p align="center">
  <img src="https://github.com/grensen/multi-core/blob/main/figures/nerfed_llms.png?raw=true">
</p>

Due to the constant changes here and there, our experience with LLMs is also changing. One problem for the providers such as OpenAI are the enormous costs that increase with every additional use of ChatGPT and co. It seems tempting to make the model even more efficient and thus reduce the costs. But this also seems to lead to decreasing quality, as you could read in many tweets where people wondered whether LLMs were becoming dumb. These types of tweets pop up on my timeline throughout the year.

## Dont waste time!

Sometimes you might not want to take an LLM for your work. Interpolation and extrapolation are strange terms, where interpolation means what we have now, and extrapolation is the way that somehow goes beyond our frame.
An LLM was trained with stuff, by that I mean a lot of text, text that was not read. In my mind, such an LLM forms an average of the trained examples. So what has been trained often it can do particularly well, but at the borders it can quickly come to some problems, and beyond the borders confused outputs are rather the rule.

LLM's not only struggle with lack of training examples, they also have to keep up with our world. ChatGPT has been trained a few times so far. However, new methods will only be learned with the next update, and will then be on the outer edge of my mental map. Here I seem to have been more often, because the results were confused and have cost me time!

**Sometimes better you do!**
